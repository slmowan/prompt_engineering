experiment:
  name: "LLM_Comparison"
  description: "Comparing ChatGPT with local open-source LLM"

models:
  local:
#    name: "meta-llama/Llama-3.2-1B-Instruct"
    name: "Qwen/Qwen2.5-1.5B-Instruct"
    # Alternative options:
    # - "meta-llama/Llama-3.2-3B-Instruct"
    # - "Qwen/Qwen2.5-0.5B-Instruct"
    # - "Qwen/Qwen2.5-1.5B-Instruct"
    # - "Qwen/Qwen2.5-3B-Instruct"
    parameters:
      max_new_tokens: 512
      temperature: 0.7
      top_p: 0.95
      repetition_penalty: 1.15
      torch_dtype: "float16"  # Options: "float16", "bfloat16", "float32"
      device_map: "auto"      # Options: "auto", "cpu", "cuda:0"

  chatgpt:
    # Placeholder for manual comparison
    interface: "web"
    model: "gpt-3.5-turbo"  # For reference only

prompt_template: "Task: {input}\nOutput:"

prompt_pairs:
  - prompt: "is this text positive or negative? Input: Today's weather is sunny and great!"
    expected: "Positive"
  - prompt: "Translate the following English text to French: 'Hello, how are you?'"
    expected: "Bonjour, comment allez-vous?"
  - prompt: "Calculate the sum of 125 + 437"
    expected: "562"
  - prompt: "Explain what photosynthesis is in one sentence."
    expected: "Photosynthesis is the process by which plants convert sunlight into energy."
  - prompt: "Generate a short haiku about autumn."
    expected: "A poem about autumn with 5-7-5 syllable structure"

output:
  save_results: true
  results_file: "llm_comparison_results.csv"
  include_full_responses: true
